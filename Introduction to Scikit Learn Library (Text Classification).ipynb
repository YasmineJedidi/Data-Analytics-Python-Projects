{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b2b9362",
   "metadata": {},
   "source": [
    "# Loading Json Data\n",
    "This file contains 10,000 book reviews from amazon with the following attributes :reviewerID, asin, reviewerName, helpful,overall, summary, unixReviewTime, and reviewTime\n",
    "\n",
    "Tutorial by [Keith Galli](https://youtu.be/M9Itm95JzL0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "5af1d360",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json #to process out json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c072c205",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"reviewerID\": \"A1F2H80A1ZNN1N\", \"asin\": \"B00GDM3NQC\", \"reviewerName\": \"Connie Correll\", \"helpful\": [0, 0], \"reviewText\": \"I bought both boxed sets, books 1-5.  Really a great series!  Start book 1 three weeks ago and just finished book 5.  Sloane Monroe is a great character and being able to follow her through both private life and her PI life gets a reader very involved!  Although clues may be right in front of the reader, there are twists and turns that keep one guessing until the last page!  These are books you won't be disappointed with.\", \"overall\": 5.0, \"summary\": \"Can't stop reading!\", \"unixReviewTime\": 1390435200, \"reviewTime\": \"01 23, 2014\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "file_name=r\"C:\\Users\\yesmi\\OneDrive\\Desktop\\Data Analytics Projects\\Projects Set 1\\Books_small_10000.json\"\n",
    "with open (file_name) as f:\n",
    "    for line in f:\n",
    "        print(line)  \n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d89f3ce3",
   "metadata": {},
   "source": [
    "We want to extract, from each line, the \"reviewText\" and the \"overall\", then assigne to each score a sentiment:\n",
    "* 1-2: negative sentiment\n",
    "* 3: neutral\n",
    "* 4-5: positive sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "96435ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "class Sentiment:\n",
    "    NEGATIVE = \"NEGATIVE\"\n",
    "    NEUTRAL = \"NEUTRAL\"\n",
    "    POSITIVE = \"POSITIVE\"\n",
    "\n",
    "class Review:\n",
    "    def __init__(self, text, score):\n",
    "        self.text = text\n",
    "        self.score = score\n",
    "        self.sentiment = self.get_sentiment()\n",
    "        \n",
    "    def get_sentiment(self):\n",
    "        if self.score <= 2:\n",
    "            #return 'NEGATIVE'\n",
    "            return Sentiment.NEGATIVE \n",
    "        elif self.score == 3:\n",
    "            #return 'NEUTRAL'\n",
    "            return Sentiment.NEUTRAL\n",
    "        else: #Score of 4 or 5\n",
    "            #return\"POSITIVE\"\n",
    "            return Sentiment.POSITIVE\n",
    "        \n",
    "class ReviewContainer:\n",
    "    def __init__(self, reviews):\n",
    "        self.reviews = reviews\n",
    "        \n",
    "    def get_text(self):\n",
    "        return [x.text for x in self.reviews]\n",
    "    \n",
    "    def get_sentiment(self):\n",
    "        return [x.sentiment for x in self.reviews]\n",
    "        \n",
    "    def evenly_distribute(self):\n",
    "        negative = list(filter(lambda x: x.sentiment == Sentiment.NEGATIVE, self.reviews))\n",
    "        positive = list(filter(lambda x: x.sentiment == Sentiment.POSITIVE, self.reviews))\n",
    "        positive_shrunk = positive[:len(negative)]\n",
    "        self.reviews = negative + positive_shrunk\n",
    "        random.shuffle(self.reviews)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeaeb56",
   "metadata": {},
   "source": [
    "The purpose of the evenly_distribute() method is to evenly distribute the reviews in the container so that there are an equal number of positive and negative reviews.\n",
    "\n",
    "The method filters the reviews into separate lists based on their sentiment (either positive or negative). Then, it shrinks the positive list to be the same length as the negative list by taking only the first n positive reviews, where n is the length of the negative list. Finally, it concatenates the two lists and shuffles them randomly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "5c86704b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = []\n",
    "with open(file_name) as f:\n",
    "    for line in f:\n",
    "        review = json.loads(line)\n",
    "        reviews.append(Review(review['reviewText'],review['overall']))\n",
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "14b68082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: I enjoyed this short book. But it was way way to short ....I can see how easily it would have been to add several chapters.\n",
      "Score: 3.0\n",
      "Sentiment: NEUTRAL\n"
     ]
    }
   ],
   "source": [
    "print(\"Text:\",reviews[1].text)\n",
    "print(\"Score:\",reviews[1].score)\n",
    "print(\"Sentiment:\",reviews[1].sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0395bd",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "24fd5395",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "a8d66308",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into training and test set\n",
    "training_set, test_set = train_test_split(reviews, test_size=0.33,random_state=40)\n",
    "\n",
    "train_container = ReviewContainer(training_set)\n",
    "\n",
    "test_container = ReviewContainer(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "91105445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423\n",
      "423\n"
     ]
    }
   ],
   "source": [
    "#The target here is the sentiment (y), and the predictor is the text (x)\n",
    "train_container.evenly_distribute()\n",
    "train_x = train_container.get_text()\n",
    "train_y = train_container.get_sentiment()\n",
    "\n",
    "test_container.evenly_distribute()\n",
    "test_x = test_container.get_text()\n",
    "test_y = test_container.get_sentiment()\n",
    "\n",
    "print(train_y.count(Sentiment.POSITIVE))\n",
    "print(train_y.count(Sentiment.NEGATIVE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7c8d6f",
   "metadata": {},
   "source": [
    "## CountVectorizer\n",
    "CountVectorizer will convert the text  to a matrix of counts. Tt creates a vocabulary of all unique words in the text corpus and assigns each word a unique integer index.\n",
    "\n",
    "This vectorization process enables us to perform statistical analysis on text data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "3a4836cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer() \n",
    "\n",
    "# vectorizer.fit(x)\n",
    "# train_x_vectors = vectorizer.transform(x)\n",
    "train_x_vectors = vectorizer.fit_transform(train_x) #converts each line into a vector of numerical values.\n",
    "test_x_vectors = vectorizer.transform(test_x) #We should not fit the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c995c72",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70731256",
   "metadata": {},
   "source": [
    "## 1. Linear SVM\n",
    "**Support Vector Machine** is used for linearly seperable binary sets. Its main goal is to design a hyperplane that classifies data into two sets with the maximum margin. The margin is the distance between the hyperplane and the closest data points from each class, which are the support vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "816a4e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "svm_model = svm.SVC(kernel='linear')\n",
    "svm_model.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "c7af4d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is an engaging, interesting, thoughtful book by a former atheist who gradually, kicking and screaming, converts to Catholicism.  A well-told conversion story with depth and humor.\n",
      "Predicted sentiment: ['POSITIVE']\n"
     ]
    }
   ],
   "source": [
    "#prediction test\n",
    "print(test_x[1])\n",
    "print('Predicted sentiment:',svm_model.predict(test_x_vectors[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231a76b7",
   "metadata": {},
   "source": [
    "## 2. Desicion Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "58d84b4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "Dec_model = DecisionTreeClassifier()\n",
    "Dec_model.fit(train_x_vectors,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "9420abef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Dec_model.predict(test_x_vectors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4db315",
   "metadata": {},
   "source": [
    "## 3. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "d5fb632b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "NB_model = GaussianNB()\n",
    "NB_model.fit(train_x_vectors.toarray(),train_y) #\"toarray\" converts a sparse matrix to a dense numpy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3ac481",
   "metadata": {},
   "source": [
    "**Why use \"toarray()\"?**\n",
    "\n",
    "When dealing with *high-dimensional* data, such as text data with a *large number of features*, the resulting feature vectors can be very sparse. In other words, most of the elements in the feature vectors are zero. In such cases, representing the feature vectors as dense numpy arrays can be computationally expensive and memory-intensive.\n",
    "\n",
    "To avoid this issue, it is common to represent sparse feature vectors as sparse matrices. A sparse matrix only stores the non-zero elements in a compressed format, which can significantly reduce memory usage and computation time. However, not all machine learning algorithms can handle sparse matrices.\n",
    "\n",
    "In the case of **GaussianNB**, it requires dense data because it assumes a *continuous distribution* for the features, which *cannot be modeled using sparse matrices*. Therefore, when using GaussianNB, we need to convert the sparse feature vectors to dense numpy arrays before fitting the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "ffde475c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NB_model.predict(test_x_vectors[1].toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba61a5f",
   "metadata": {},
   "source": [
    "## 4. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "ca26ff5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "LR_model = LogisticRegression()\n",
    "LR_model.fit(train_x_vectors,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "2edc7544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LR_model.predict(test_x_vectors[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b861395d",
   "metadata": {},
   "source": [
    "# Model Analysis and Evaluation\n",
    "## 1. Compare Accuracy\n",
    "The **mean accuracy** of a classifier is a measure of how often the classifier correctly predicts the class label for the entire dataset. It is the ratio of the number of correctly predicted samples to the total number of samples in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "e833b3e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Classifier Accuracy: 0.8552036199095022\n",
      "Decision Tree Classifier Accuracy: 0.6764705882352942\n",
      "Naive Bayes Classifier Accuracy: 0.6176470588235294\n",
      "Logistic Regression Classifier Accuracy: 0.8506787330316742\n"
     ]
    }
   ],
   "source": [
    "print(\"SVM Classifier Accuracy:\",svm_model.score(test_x_vectors,test_y)) \n",
    "print(\"Decision Tree Classifier Accuracy:\",Dec_model.score(test_x_vectors,test_y))\n",
    "print(\"Naive Bayes Classifier Accuracy:\",NB_model.score(test_x_vectors.toarray(),test_y))\n",
    "print(\"Logistic Regression Classifier Accuracy:\",LR_model.score(test_x_vectors.toarray(),test_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b4c5c1f",
   "metadata": {},
   "source": [
    "## 2. F1 Score\n",
    "The F1 score is a weighted average of precision and recall. It measures the balance between the **precision** (the number of true positives divided by the number of true positives plus false positives) and **recall** (the number of true positives divided by the number of true positives plus false negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "06c257ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.85253456, 0.85777778])"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# f1_score(test_y, svm_model.predict(test_x_vectors), average= None, \n",
    "#          labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE])\n",
    "#SVM \n",
    "f1_score(test_y, svm_model.predict(test_x_vectors), average= None, \n",
    "         labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "59590546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66510539, 0.68708972])"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Decision tree\n",
    "f1_score(test_y, Dec_model.predict(test_x_vectors), average= None, \n",
    "         labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "3449becf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yesmi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.60788863, 0.        , 0.62693157])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Naive Bayes\n",
    "f1_score(test_y, NB_model.predict(test_x_vectors.toarray()), average= None, \n",
    "         labels=[Sentiment.POSITIVE, Sentiment.NEUTRAL, Sentiment.NEGATIVE])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "a785ff55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.84862385, 0.85267857])"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Logistic Regression\n",
    "f1_score(test_y, LR_model.predict(test_x_vectors), average= None, \n",
    "         labels=[Sentiment.POSITIVE, Sentiment.NEGATIVE])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f836512",
   "metadata": {},
   "source": [
    "## Qualitative Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "3dc70f1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NEGATIVE', 'NEGATIVE', 'NEGATIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = [\"very good. excellent book\",\"terrible book, do not recommend\", \"wouldn't recommend it to my worst enenmies\"]\n",
    "\n",
    "vect_test = vectorizer.transform(test)\n",
    "\n",
    "NB_model.predict(vect_test.toarray())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332a3b29",
   "metadata": {},
   "source": [
    "# Tuning the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "c307569b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=SVC(),\n",
       "             param_grid={'C': (1, 4, 8, 16, 32), 'kernel': ('linear', 'rbf')})"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = {'kernel': ('linear', 'rbf'), 'C': (1,4,8,16,32)}\n",
    "\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters, cv=5)\n",
    "\n",
    "clf.fit(train_x_vectors, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "584086b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8484162895927602"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_x_vectors, test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77acc621",
   "metadata": {},
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "3598292e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open (r'C:\\Users\\yesmi\\OneDrive\\Desktop\\Data Analytics Projects\\Projects Set 1\\Models\\SVM_sentiment_classifier.pkl'\n",
    "          ,'wb') as f:\n",
    "\n",
    "    pickle.dump(clf, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0373a9",
   "metadata": {},
   "source": [
    "This code saves the trained clf model using Python's pickle module. The model is saved in binary format to the file sentiment_classifier.pkl located in the ./models directory.\n",
    "\n",
    "The with open(...) block opens the file for writing using the 'wb' mode, which means that the file is opened for writing in binary mode. The pickle.dump() function then writes the clf object to the file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14102a8",
   "metadata": {},
   "source": [
    "## Loading the Model\n",
    "Use a loaded model without training it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "7579bfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (r'C:\\Users\\yesmi\\OneDrive\\Desktop\\Data Analytics Projects\\Projects Set 1\\Models\\SVM_sentiment_classifier.pkl', 'rb') as f:\n",
    "    loaded_clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "9566cd53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Constance Cherry's book is a wealth of information.  What a fresh way to look at worship planning!  I highly recommend to worship planners and worshipers alike!\""
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "d86567fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['POSITIVE'], dtype='<U8')"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_clf.predict(test_x_vectors[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
